# ğŸ” Data Search Agent

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-powered-green.svg)](https://github.com/langchain-ai/langgraph)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

An intelligent **LangGraph-based agent** for semantic table search in enterprise Data Lakes. Designed to act as an autonomous Data Steward, navigating complex data catalogs to find the right information.

## âœ¨ Features

- **Hierarchical Search** â€“ Navigate through Domain â†’ Owner â†’ Table levels
- **Hybrid RAG Pipeline** â€“ Dense + Sparse retrieval with multi-vector search
- **LLM Reranking** â€“ Smart result ordering using GPT models
- **Disambiguation Scoring** â€“ Intelligent scoring to separate production tables from drafts/legacy
- **Column-Level Search** â€“ Find tables by their column names and types
- **Feedback Learning** â€“ Improves over time based on user interactions

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    Start([User Query]) --> Intent[Intent Normalizer]

    subgraph "Hierarchical Navigation"
        Intent --> Domain[Domain Search]
        Domain --> Owner[Owner Search]
    end

    subgraph "Hybrid RAG"
        Owner --> Tables[Vector Table Search]
        Owner --> Columns[Column Search]
        Tables --> Merge[Result Fusion]
        Columns --> Merge
    end

    subgraph "Cognitive Refinement"
        Merge --> Rerank[LLM Reranking]
        Rerank --> Disambiguation[Scoring & Disambiguation]
        Disambiguation --> Decision[Final Decision]
    end

    Decision --> End([Response])
```

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/o-lino/data-search-agent.git
cd data-search-agent

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

## âš™ï¸ Configuration

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_openai_api_key
CHROMA_PERSIST_DIRECTORY=./data/chroma
```

## ğŸš€ Quick Start

```python
from graph import get_agent, create_initial_state

# Initialize the agent
agent = get_agent()

# Create initial state with your query
state = create_initial_state(query="Find customer transaction tables")

# Run the agent
result = agent.invoke(state)
print(result)
```

### Running the API Server

```bash
uvicorn admin_api:app --reload --port 8000
```

## ğŸ“ Project Structure

```
data-search-agent/
â”œâ”€â”€ agent/              # Agent core logic
â”œâ”€â”€ disambiguation/     # Scoring and disambiguation algorithms
â”œâ”€â”€ docs/               # Architecture and user guides
â”œâ”€â”€ indexing/           # Data ingestion and vectorization
â”œâ”€â”€ knowledge/          # Domain knowledge base
â”œâ”€â”€ llm/                # LLM integration layer
â”œâ”€â”€ memory/             # Conversation and feedback memory
â”œâ”€â”€ metrics/            # Performance metrics
â”œâ”€â”€ monitoring/         # Health checks and observability
â”œâ”€â”€ nodes/              # LangGraph node implementations
â”œâ”€â”€ quality/            # Data quality scoring
â”œâ”€â”€ rag/                # RAG pipeline components
â”œâ”€â”€ tests/              # Test suite
â”œâ”€â”€ tools/              # Agent tools
â”œâ”€â”€ graph.py            # Main graph orchestration
â”œâ”€â”€ state.py            # Agent state definitions
â””â”€â”€ admin_api.py        # FastAPI admin endpoints
```

## ğŸ“– Documentation

- [Architecture Guide](docs/ARCHITECTURE.md) â€“ System design and components
- [User Guide](docs/USER_GUIDE.md) â€“ How to use the agent
- [Decision Logic](docs/DECISION_LOGIC.md) â€“ Understanding the ranking algorithm
- [Performance Report](docs/PERFORMANCE_REPORT.md) â€“ Benchmarks and metrics

## ğŸ³ Docker

```bash
# Build and run with Docker Compose
docker-compose up --build
```

## ğŸ§ª Testing

```bash
# Run tests
python -m pytest tests/
```

## ğŸ“Š Disambiguation Scoring

The agent uses a weighted formula to rank results:

| Factor              | Weight | Description                                   |
| ------------------- | ------ | --------------------------------------------- |
| Semantic Similarity | 25%    | How well the table matches your query         |
| Technical Quality   | 50%    | Golden Source status, freshness, data quality |
| Historical Usage    | 15%    | Approved by other users for similar queries   |
| Owner Relevance     | 10%    | Is the owner appropriate for your domain?     |

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Built with â¤ï¸ using LangGraph, ChromaDB, and OpenAI**
